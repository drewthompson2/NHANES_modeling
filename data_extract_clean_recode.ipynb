{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "import psycopg2\n",
    "dbname = 'cdc'\n",
    "username = 'Drew'\n",
    "engine = create_engine('postgres://%s@localhost/%s'%(username,dbname))\n",
    "if not database_exists(engine.url):\n",
    "    create_database(engine.url)\n",
    "print(database_exists(engine.url))\n",
    "con = psycopg2.connect(database = dbname, user = username)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (All data available in .xpt format from https://wwwn.cdc.gov/Nchs/Nhanes/ContinuousNhanes/Default.aspx)\n",
    "### At the time of this project, datasets from 1999 through 2013 were available, binned into ~10,000 samples per every 2 years\n",
    "##### Note that many questions from the survey offer a 'don't know' or 'refused to answer' catogory.  Unfortunately the coding of these responses varies from question to question (depending on range, they take on values of 7, 77, 777... up to 777777, and likewise with 9, 99, 999...  As data is cleaned and combined, these values are recoded to numpy.nans, to be dealt with via dropping/imputation once we get to the modeling section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TARGETS: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blood Pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import and combine data sets from 1999-2013\n",
    "bpx99 = pd.read_csv('CDCfiles/BPX.csv')\n",
    "bpx01 = pd.read_csv('CDCfiles/BPX_B.csv')\n",
    "bpx03 = pd.read_csv('CDCfiles/BPX_C.csv')\n",
    "bpx05 = pd.read_csv('CDCfiles/BPX_D.csv')\n",
    "bpx07 = pd.read_csv('CDCfiles/BPX_E.csv')\n",
    "bpx09 = pd.read_csv('CDCfiles/BPX_F.csv')\n",
    "bpx11 = pd.read_csv('CDCfiles/BPX_G.csv')\n",
    "bpx13 = pd.read_csv('CDCfiles/BPX_H.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# join together years 1999-2013\n",
    "bpx = bpx99.append(bpx01).append(bpx03).append(bpx05).append(bpx07).append(bpx09).append(bpx11).append(bpx13)\n",
    "\n",
    "# recode blood pressure (systolic and diastolic) as average of 2 separate measurements\n",
    "bpx['BPXsys'] = bpx[['BPXSY1', 'BPXSY2']].mean(axis=1)\n",
    "bpx['BPXdi'] = bpx[['BPXDI1', 'BPXDI2']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pull out just the measurements we want\n",
    "bpxF = bpx[['SEQN', 'BPXsys', 'BPXdi']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cholesterol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import all years of datasets containing measurements of HDL, LDL, total cholesterol, and triglycerides\n",
    "chol99HD = pd.read_csv('CDCfiles/LAB13.csv')\n",
    "chol01HD = pd.read_csv('CDCfiles/L13_B.csv')\n",
    "chol03HD = pd.read_csv('CDCfiles/L13_C.csv')\n",
    "chol05HD = pd.read_csv('CDCfiles/HDL_D.csv')\n",
    "chol07HD = pd.read_csv('CDCfiles/HDL_E.csv')\n",
    "chol09HD = pd.read_csv('CDCfiles/HDL_F.csv')\n",
    "chol11HD = pd.read_csv('CDCfiles/HDL_G.csv')\n",
    "chol13HD = pd.read_csv('CDCfiles/HDL_H.csv')\n",
    "\n",
    "chol99LD = pd.read_csv('CDCfiles/LAB13AM.csv')\n",
    "chol01LD = pd.read_csv('CDCfiles/L13AM_B.csv')\n",
    "chol03LD = pd.read_csv('CDCfiles/L13AM_C.csv')\n",
    "chol05LD = pd.read_csv('CDCfiles/TRIGLY_D.csv')\n",
    "chol07LD = pd.read_csv('CDCfiles/TRIGLY_E.csv')\n",
    "chol09LD = pd.read_csv('CDCfiles/TRIGLY_F.csv')\n",
    "chol11LD = pd.read_csv('CDCfiles/TRIGLY_G.csv')\n",
    "chol13LD = pd.read_csv('CDCfiles/TRIGLY_H.csv')\n",
    "\n",
    "chol05tot = pd.read_csv('CDCfiles/TCHOL_D.csv')\n",
    "chol07tot = pd.read_csv('CDCfiles/TCHOL_E.csv')\n",
    "chol09tot = pd.read_csv('CDCfiles/TCHOL_F.csv')\n",
    "chol11tot = pd.read_csv('CDCfiles/TCHOL_G.csv')\n",
    "chol13tot = pd.read_csv('CDCfiles/TCHOL_H.csv')\n",
    "\n",
    "# join together separate measurements into a single file for each year\n",
    "chol99 = chol99HD.set_index('SEQN').join(chol99LD.set_index('SEQN'))\n",
    "chol01 = chol01HD.set_index('SEQN').join(chol01LD.set_index('SEQN'))\n",
    "chol03 = chol03HD.set_index('SEQN').join(chol03LD.set_index('SEQN'))\n",
    "chol05 = chol05tot.set_index('SEQN').join(chol05HD.set_index('SEQN')).join(chol05LD.set_index('SEQN'))\n",
    "chol07 = chol07tot.set_index('SEQN').join(chol07HD.set_index('SEQN')).join(chol07LD.set_index('SEQN'))\n",
    "chol09 = chol09tot.set_index('SEQN').join(chol09HD.set_index('SEQN')).join(chol09LD.set_index('SEQN'))\n",
    "chol11 = chol11tot.set_index('SEQN').join(chol11HD.set_index('SEQN')).join(chol11LD.set_index('SEQN'))\n",
    "chol13 = chol13tot.set_index('SEQN').join(chol13HD.set_index('SEQN')).join(chol13LD.set_index('SEQN'))\n",
    "\n",
    "#recode measurements from older studies to match same measurements from more recent studies\n",
    "chol99['LBDHDD'] = chol99['LBDHDL']\n",
    "chol01['LBDHDD'] = chol01['LBDHDL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# join together years 1999-2013\n",
    "chol = chol99.append(chol01).append(chol03).append(chol05).append(chol07).append(chol09).append(chol11).append(chol13)\n",
    "chol['SEQN'] = chol.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pull out just the measurements we want\n",
    "cholF = chol[['SEQN', 'LBXTC', 'LBDHDD', 'LBDLDL', 'LBXTR']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import all years of datasets\n",
    "ghb99 = pd.read_csv('CDCfiles/GHB.csv')\n",
    "ghb01 = pd.read_csv('CDCfiles/GHB_B.csv')\n",
    "ghb03 = pd.read_csv('CDCfiles/GHB_C.csv')\n",
    "ghb05 = pd.read_csv('CDCfiles/GHB_D.csv')\n",
    "ghb07 = pd.read_csv('CDCfiles/GHB_E.csv')\n",
    "ghb09 = pd.read_csv('CDCfiles/GHB_F.csv')\n",
    "ghb11 = pd.read_csv('CDCfiles/GHB_G.csv')\n",
    "ghb13 = pd.read_csv('CDCfiles/GHB_H.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#join together years 1999-2013\n",
    "ghb = ghb99.append(ghb01).append(ghb03).append(ghb05).append(ghb07).append(ghb09).append(ghb11).append(ghb13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pull out just the measurements we want\n",
    "ghbF = ghb[['SEQN', 'LBXGH']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURES:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demographics - 82,091 entires total\n",
    "\n",
    "'RIAGENDR' =  1-male  // 2-female  \n",
    "'RIDAGEYR' =  0-85 numerical  \n",
    "'RIDRETH1 =  categorical ethnicity, for get_dummies  \n",
    "'DMDBORN4' =  1-US // 2-elsewhere    \n",
    "'DMDEDUC2' =  1: less then high school through //  5:college or higher    ......NANs: 50%      \n",
    "'DMDMARTL' =  1: married // 2: divorced/widowed  // 3: never married   ......NANs: 50%  \n",
    "'INDHHIN2' =  income binned as 1: 20k // 2: 20-75k // 3: 75k  ......NANs: 7%    \n",
    "'DMDHHSIZ' =  household size 0-7 numerical  \n",
    "'INDFMPIR' =  ratio of income/poverty line      ......NANs 10%  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import all years of demographics info\n",
    "demo99 = pd.read_csv('CDCfiles/DEMO.csv')\n",
    "demo01 = pd.read_csv('CDCfiles/DEMO_B.csv')\n",
    "demo03 = pd.read_csv('CDCfiles/DEMO_C.csv')\n",
    "demo05 = pd.read_csv('CDCfiles/DEMO_D.csv')\n",
    "demo07 = pd.read_csv('CDCfiles/DEMO_E.csv')\n",
    "demo09 = pd.read_csv('CDCfiles/DEMO_F.csv')\n",
    "demo11 = pd.read_csv('CDCfiles/DEMO_G.csv')\n",
    "demo13 = pd.read_csv('CDCfiles/DEMO_H.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# combine years 1999 through 2005, which have common codes\n",
    "demoold = demo99.append(demo01).append(demo03).append(demo05)\n",
    "\n",
    "# recode country of birth to the name used in later years, convert to 2 class problem (born in US vs not in US)\n",
    "demoold['DMDBORN4'] = demoold['DMDBORN']\n",
    "demoold['DMDBORN4'][demoold['DMDBORN'] == 3.0] = 2.0\n",
    "\n",
    "# recode income into 3 categories\n",
    "demoold['INDHHIN2'] = demoold['INDHHINC']\n",
    "demoold['INDHHIN2'][demoold['INDHHIN2'] < 5.0] = 1.0\n",
    "demoold['INDHHIN2'][demoold['INDHHIN2'] == 13.0] = 1.0\n",
    "demoold['INDHHIN2'][demoold['INDHHIN2'] == 11.0] = 3.0\n",
    "demoold['INDHHIN2'][demoold['INDHHIN2'] > 75.0] = np.nan\n",
    "demoold['INDHHIN2'][demoold['INDHHIN2'] > 4.0] = 2.0\n",
    "\n",
    "# recode elements as they change in 2007, 2009\n",
    "demo07['DMDBORN4'] = demo07['DMDBORN2']\n",
    "demo07['DMDBORN4'][demo07['DMDBORN4'] == 4.0] = 2.0\n",
    "demo07['DMDBORN4'][demo07['DMDBORN4'] == 5.0] = 2.0\n",
    "\n",
    "demo09['DMDBORN4'] = demo09['DMDBORN2']\n",
    "demo09['DMDBORN4'][demo09['DMDBORN4'] == 4.0] = 2.0\n",
    "demo09['DMDBORN4'][demo09['DMDBORN4'] == 5.0] = 2.0\n",
    "\n",
    "#recode race in later years back into the RIDRETH1 variabel, but maintain tje new 'asian' class\n",
    "demo11['RIDRETH1'][demo11['RIDRETH3'] == 6.0] = 6.0\n",
    "demo13['RIDRETH1'][demo13['RIDRETH3'] == 6.0] = 6.0\n",
    "demo11['RIDRETH1'][demo11['RIDRETH3'] == 7.0] = 5.0\n",
    "demo13['RIDRETH1'][demo13['RIDRETH3'] == 7.0] = 5.0\n",
    "\n",
    "#combine 2007 through 2013\n",
    "demonew = demo07.append(demo09).append(demo11).append(demo13)\n",
    "\n",
    "# recode income into the bins described above\n",
    "demonew['INDHHIN2'][demonew['INDHHIN2'] < 5.0] = 1.0\n",
    "demonew['INDHHIN2'][demonew['INDHHIN2'] == 13.0] = 1.0\n",
    "demonew['INDHHIN2'][demonew['INDHHIN2'] == 14.0] = 3.0\n",
    "demonew['INDHHIN2'][demonew['INDHHIN2'] == 15.0] = 3.0\n",
    "demonew['INDHHIN2'][demonew['INDHHIN2'] > 75.0] = np.nan\n",
    "demonew['INDHHIN2'][demonew['INDHHIN2'] > 4.0] = 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# combine demoold (1999-2005) with demonew (2007-2013)\n",
    "demo = demoold.append(demonew)\n",
    "\n",
    "# recode gender so 0 = female, 1 = male\n",
    "demo['RIAGENDR'][demo['RIAGENDR'] == 2.0] = 0.0\n",
    "\n",
    "# recode age so that years including subjects > 80 are recoded to 80\n",
    "demo['RIDAGEYR'][demo['RIDAGEYR'] > 80.0] = 80.0\n",
    "\n",
    "# recode missing values\n",
    "demo['DMDBORN4'][demo['DMDBORN4'] > 3.0] = np.nan\n",
    "demo['DMDEDUC2'][demo['DMDEDUC2'] > 6.0] = np.nan\n",
    "\n",
    "# convert marital stats answers to 3 categories described above\n",
    "demo['DMDMARTL'][demo['DMDMARTL'] == 6.0] = 1.0\n",
    "demo['DMDMARTL'][demo['DMDMARTL'] == 3.0] = 2.0\n",
    "demo['DMDMARTL'][demo['DMDMARTL'] == 4.0] = 2.0\n",
    "demo['DMDMARTL'][demo['DMDMARTL'] == 5.0] = 3.0\n",
    "demo['DMDMARTL'][demo['DMDMARTL'] > 70.0] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pull out just the measurements we want\n",
    "demoF = demo[['SEQN', 'RIAGENDR', 'RIDAGEYR', 'DMDBORN4', 'DMDEDUC2', 'INDHHIN2', 'DMDHHSIZ', 'DMDMARTL', 'INDFMPIR']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert racial background to one-hot encoding\n",
    "demoFhot = (pd.get_dummies(demo.RIDRETH1))\n",
    "demoFdummy = pd.concat([demoF, demoFhot], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Body Type - 68,705 entries\n",
    "\n",
    "'BMXHT' is missing 10%\n",
    "'BMXWT' is missing 2%  \n",
    "'BMXBMI' is missing 10%   \n",
    "'BMXWAIST' is missing 13%   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import data from 1999-2013\n",
    "body99 = pd.read_csv('CDCfiles/BMX.csv')\n",
    "body01 = pd.read_csv('CDCfiles/BMX_B.csv')\n",
    "body03 = pd.read_csv('CDCfiles/BMX_C.csv')\n",
    "body05 = pd.read_csv('CDCfiles/BMX_D.csv')\n",
    "body07 = pd.read_csv('CDCfiles/BMX_E.csv')\n",
    "body09 = pd.read_csv('CDCfiles/BMX_F.csv')\n",
    "body11 = pd.read_csv('CDCfiles/BMX_G.csv')\n",
    "body13 = pd.read_csv('CDCfiles/BMX_H.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# combine data from 1999-2013\n",
    "body = body99.append(body01).append(body03).append(body05).append(body07).append(body09).append(body11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pull out just the features we want\n",
    "bodyF = body[['SEQN', 'BMXWT', 'BMXHT', 'BMXBMI', 'BMXWAIST']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alcohol Use - 42,291 entries\n",
    "\n",
    "'ALQ120U/Q' = how often you drank in the last 12 months     .........NANs: 25%  \n",
    "'ALQ130' ...= avg # of drinks on those occasions when you drank  ......NANs: 25%  \n",
    "'ALQpoly' ..= 120x130 = how much you drank in the last year  ......NANs: 25%   \n",
    "'ALQ141U/Q' = how often you had >4 drinks in last 12 months  ......NANs: 40% (mostly 0's though)    \n",
    "'ALQ151' ...= yes/no ever had a phase of >4 drinks every day  ...... NANs: 25%\n",
    "\n",
    "\n",
    "__try dropping NANs from ALQ120, then imputing those that remain (keep the ALQ141 NANs)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import all datasets from 1999-2013\n",
    "alc99 = pd.read_csv('CDCfiles/ALQ.csv')\n",
    "alc01 = pd.read_csv('CDCfiles/ALQ_B.csv')\n",
    "alc03 = pd.read_csv('CDCfiles/ALQ_C.csv')\n",
    "alc05 = pd.read_csv('CDCfiles/ALQ_D.csv')\n",
    "alc07 = pd.read_csv('CDCfiles/ALQ_E.csv')\n",
    "alc09 = pd.read_csv('CDCfiles/ALQ_F.csv')\n",
    "alc11 = pd.read_csv('CDCfiles/ALQ_G.csv')\n",
    "alc13 = pd.read_csv('CDCfiles/ALQ_H.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combine data from 1999-2009\n",
    "alcold = alc99.append(alc01).append(alc03).append(alc05).append(alc07).append(alc09)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# recode to match the coding post 2009\n",
    "alcold['ALQ141Q'] = alcold['ALQ140Q']\n",
    "alcold['ALQ141U'] = alcold['ALQ140U']\n",
    "alcold['ALQ151'] = alcold['ALQ150']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combine alcold with data from 2011 and 2013 (with the same coding)\n",
    "alc = alcold.append(alc11).append(alc13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert NaNs in unit column (and 130) to 0.0 where quantity = 0.0 (to preserve 0s after multiplication step)\n",
    "alc['ALQ120U'][alc['ALQ120Q'] == 0.0] = 0.0\n",
    "alc['ALQ130'][alc['ALQ120Q'] == 0.0] = 0.0\n",
    "alc['ALQ141U'][alc['ALQ141Q'] == 0.0] = 0.0\n",
    "#recode NaNs\n",
    "alc['ALQ120Q'][alc['ALQ120Q'] > 775.0] = np.nan\n",
    "alc['ALQ141Q'][alc['ALQ141Q'] > 775.0] = np.nan\n",
    "alc['ALQ130'][alc['ALQ130'] > 750] = np.nan\n",
    "alc['ALQ151'][alc['ALQ151'] > 6.0] = np.nan\n",
    "\n",
    "# fix the scaling for the unit column, then multiply with the quantity column\n",
    "alc['ALQ120U'] = alc['ALQ120U'].replace([0.0, 1.0, 2.0, 3.0, 7.0, 9.0], [0.0, 52.0, 12.0, 1.0, np.nan, np.nan])\n",
    "alc['ALQ141U'] = alc['ALQ141U'].replace([0.0, 1.0, 2.0, 3.0, 7.0, 9.0], [0.0, 52.0, 12.0, 1.0, np.nan, np.nan])\n",
    "alc['ALQ120'] = alc['ALQ120Q']*alc['ALQ120U']\n",
    "alc['ALQ141'] = alc['ALQ141Q']*alc['ALQ141U']\n",
    "\n",
    "# create ALQpoly by multiplying frequency of drinking by volume\n",
    "alc['ALQpoly'] = alc['ALQ120']*alc['ALQ130']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pull out just the features we want\n",
    "alcF = alc[['SEQN', 'ALQ120', 'ALQ130', 'ALQ141', 'ALQ151', 'ALQpoly']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dietary questionnaire - 82,091 (highly varied, will include all relevant for filtering later)\n",
    "\n",
    "__from 99:__  \n",
    "'DBQ100' - add salts  \n",
    "'DBD270d' = helpings vegetables/day?  \n",
    "__from 01__:  \n",
    "'DBD102' = dark green vegetables /month    ...(9,000 responses)  \n",
    "'DBD103' = cooked dried beans/peas  \n",
    "__from 05, 07, 09, 11, 13:__  \n",
    "'DBQ700' = how healthy is diet, generally  .........NANs: 2/5  \n",
    "'DBD900' = # of meals from fast-food/pizza / week    .... NANs 1/4     \n",
    "'DBD910' = # of frozen meals/pizzas / week .......NANs 1/10  \n",
    "__all datasets:__  \n",
    "x'DBQ197' = past 30 days milk consumption  \n",
    "x'DBQ223' = type milk consumed  \n",
    "'DBQpoly' = type milk * rate consumed......  \n",
    "'DBQ235A/B/C' = milk over the ages  \n",
    "'DBD895'. = # meals not home prepared/week  ......NANs: 1/10 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import data from 1999-2013\n",
    "dbq99 = pd.read_csv('CDCfiles/DBQ.csv')\n",
    "dbq01 = pd.read_csv('CDCfiles/DBQ_B.csv')\n",
    "dbq03 = pd.read_csv('CDCfiles/DBQ_C.csv')\n",
    "dbq05 = pd.read_csv('CDCfiles/DBQ_D.csv')\n",
    "dbq07 = pd.read_csv('CDCfiles/DBQ_E.csv')\n",
    "dbq09 = pd.read_csv('CDCfiles/DBQ_F.csv')\n",
    "dbq11 = pd.read_csv('CDCfiles/DBQ_G.csv')\n",
    "dbq13 = pd.read_csv('CDCfiles/DBQ_H.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######  RECODE 1999\n",
    "dbq99['DBQ197'] = dbq99['DBD195'] \n",
    "dbq99['DBD895'] = dbq99['DBD090']\n",
    "dbq99['DBD895'][dbq99['DBD895'] == 6666] = 0\n",
    "\n",
    "dbq99['DBQ223A'] = dbq99['DBQ220A']\n",
    "dbq99['DBQ223B'] = dbq99['DBQ220B']\n",
    "dbq99['DBQ223C'] = dbq99['DBQ220C']\n",
    "dbq99['DBQ223D'] = dbq99['DBQ220D']\n",
    "dbq99['DBQ235A'] = dbq99['DBD235A']\n",
    "dbq99['DBQ235B'] = dbq99['DBD235B']\n",
    "dbq99['DBQ235C'] = dbq99['DBD235C']\n",
    "\n",
    "##### RECODE 2001\n",
    "dbq01['DBQ197'] = dbq01['DBD196']\n",
    "dbq01['DBD895'] = dbq01['DBD090']\n",
    "dbq01['DBD895'][dbq01['DBD895'] == 6666] = 0\n",
    "\n",
    "dbq01['DBQ223A'] = dbq01['DBD221A']\n",
    "dbq01['DBQ223B'] = dbq01['DBD221B']\n",
    "dbq01['DBQ223C'] = dbq01['DBD221C']\n",
    "dbq01['DBQ223D'] = dbq01['DBD221D']\n",
    "dbq01['DBQ235A'] = dbq01['DBD235AE']\n",
    "dbq01['DBQ235B'] = dbq01['DBD235BE']\n",
    "dbq01['DBQ235C'] = dbq01['DBD235CE']\n",
    "\n",
    "##### recode 2003\n",
    "dbq03['DBQ197'] = dbq03['DBD197']\n",
    "dbq03['DBD895'] = dbq03['DBD090']\n",
    "dbq03['DBD895'][dbq03['DBD895'] == 6666] = 0\n",
    "\n",
    "dbq03['DBQ223A'] = dbq03['DBQ221A']\n",
    "dbq03['DBQ223B'] = dbq03['DBQ221B']\n",
    "dbq03['DBQ223C'] = dbq03['DBQ221C']\n",
    "dbq03['DBQ223D'] = dbq03['DBQ221D']\n",
    "\n",
    "#### recode 2005\n",
    "dbq05['DBD895'] = dbq05['DBD091']\n",
    "dbq05['DBD895'][dbq05['DBD895'] == 6666] = 0\n",
    "\n",
    "dbq05['DBQ223A'] = dbq05['DBD222A']\n",
    "dbq05['DBQ223B'] = dbq05['DBD222B']\n",
    "dbq05['DBQ223C'] = dbq05['DBD222C']\n",
    "dbq05['DBQ223D'] = dbq05['DBD222D']\n",
    "\n",
    "##### recode 2007\n",
    "dbq07['DBQ223A'] = dbq07['DBD222A']\n",
    "dbq07['DBQ223B'] = dbq07['DBD222B']\n",
    "dbq07['DBQ223C'] = dbq07['DBD222C']\n",
    "dbq07['DBQ223D'] = dbq07['DBD222D']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combine data from 2003-2013\n",
    "dbqnew = dbq03.append(dbq05).append(dbq07).append(dbq09).append(dbq11).append(dbq13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# recode NaNs\n",
    "dbqnew['DBQ700'][dbqnew['DBQ700'] > 6.0] = np.nan\n",
    "\n",
    "# recode fast-food NaNs to 0 where meals out = 0.0\n",
    "dbqnew['DBD900'][dbqnew['DBD895'] == 0.0] = 0.0\n",
    "# recode >22 meals out / week to 22\n",
    "dbqnew['DBD900'][dbqnew['DBD900'] == 5555] = 22\n",
    "# recode NaNS\n",
    "dbqnew['DBD900'][dbqnew['DBD900'] > 7750.0] = np.nan\n",
    "dbqnew['DBD910'][dbqnew['DBD910'] > 7750.0] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combine 1999 and 2001 with post 2001\n",
    "dbq = dbq99.append(dbq01).append(dbqnew)\n",
    "\n",
    "# recode NaNs\n",
    "dbq['DBQ197'][dbq['DBQ197'] > 6.0] = np.nan\n",
    "dbq['DBQ197'][dbq['DBQ197'] == 4.0] = 2.0\n",
    "\n",
    "# recoding milk fat: 5=whole, 3=reduced, 2= lowfat , 1=skim:\n",
    "dbq['DBQ223'] = np.nan\n",
    "dbq['DBQ223'][dbq['DBQ223A'] == 10.0] = 5.0\n",
    "dbq['DBQ223'][dbq['DBQ223B'] == 11.0] = 3.0\n",
    "dbq['DBQ223'][dbq['DBQ223C'] == 12.0] = 2.0\n",
    "dbq['DBQ223'][dbq['DBQ223D'] == 13.0] = 1.0\n",
    "dbq['DBQpoly'] = dbq['DBQ197']*dbq['DBQ223']\n",
    "\n",
    "# recode > 22 meals out /week to 22, recode NaNs \n",
    "dbq['DBD895'][dbq['DBD895'] == 5555] = 22\n",
    "dbq['DBD895'][dbq['DBD895'] > 7000] = np.nan\n",
    "\n",
    "#recode NaNs\n",
    "dbq['DBQ235A'][dbq['DBQ235A'] == 4.0] = 2.0\n",
    "dbq['DBQ235A'][dbq['DBQ235A'] > 5.0] = np.nan\n",
    "dbq['DBQ235B'][dbq['DBQ235B'] == 4.0] = 2.0\n",
    "dbq['DBQ235B'][dbq['DBQ235B'] > 5.0] = np.nan \n",
    "dbq['DBQ235C'][dbq['DBQ235C'] == 4.0] = 2.0\n",
    "dbq['DBQ235C'][dbq['DBQ235C'] > 5.0] = np.nan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pull out the just features we want\n",
    "dbqF = dbq[['SEQN', 'DBD895', 'DBQ197', 'DBQ223', 'DBQpoly', 'DBQ235A', 'DBQ235B', 'DBQ235C', 'DBQ700', 'DBD900', 'DBD910']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Physical activity - 75,705 entries (varied)\n",
    "\n",
    "'PAQ635' (/620) - bike/walk 10 minutes continously?  yes/no?   ...__NANs 25%__  \n",
    "'PAQ640' (/050Q, scale U) - frequency of biking/walking  ...__NANs 25%__  \n",
    "'PAD645' : # minutes per typical bike/walk  \n",
    "'PAD645min' (/080) - avg # minutes walking/biking per trip  ...__NANs 25%__  \n",
    "'PADvig1' : vigorous activity yes/no    \n",
    "'PADvig2' : vigorous activity times/month   \n",
    "'PADmod1' : moderate activity yes/no  \n",
    "'PADmod2' : moderate activity times/month   \n",
    "'PADtvcomp' : hours per day  \n",
    "'PADtvpoly' : squared  \n",
    "\n",
    "including both PAD645 (minutes biking walking/trip) AND PAD645min (multiplied by frequency (640)  \n",
    "paqold.PAQMOD1 is taking YES from both house-tasks and moderate activity question (but only 50% overlap)\n",
    "#### possible additions from old:\n",
    "PAQ100 x PAD120 x PAD160 = (tasks around home/yard > light sweating or heartrate, NANs 30%)  \n",
    "PAQ180 = avg level of physical activity each day (categorical) (NANs: 30%)  \n",
    "Muscle Strengthening activities?  \n",
    "PAQ560: times per week you play exercise hard?  (70% NANs)\n",
    "PAQ540: compare with activity 10 yrs ago?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import data form 1999 - 2013\n",
    "paq99 = pd.read_csv('CDCfiles/PAQ.csv')\n",
    "paq01 = pd.read_csv('CDCfiles/PAQ_B.csv')\n",
    "paq03 = pd.read_csv('CDCfiles/PAQ_C.csv')\n",
    "paq05 = pd.read_csv('CDCfiles/PAQ_D.csv')\n",
    "paq07 = pd.read_csv('CDCfiles/PAQ_E.csv')\n",
    "paq09 = pd.read_csv('CDCfiles/PAQ_F.csv')\n",
    "paq11 = pd.read_csv('CDCfiles/PAQ_G.csv')\n",
    "paq13 = pd.read_csv('CDCfiles/PAQ_H.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# recode sedentary time into variable \"PADTVcomp\" \n",
    "paqolder = paq99.append(paq01)\n",
    "paqolder['PADtvcomp'] = paqolder['PAQ480']\n",
    "paqolder['PADtvcomp'][paqolder['PADtvcomp'] == 6.0] = 0.0\n",
    "paqolder['PADtvcomp'][paqolder['PADtvcomp'] > 70.0] = np.nan   \n",
    "paqolder['PADtvpoly'] = paqolder['PADtvcomp']*paqolder['PADtvcomp']\n",
    "\n",
    "paqmid = paq03.append(paq05)\n",
    "paqmid['PAD590'][paqmid['PAD590'] == 6.0] = 0.0\n",
    "paqmid['PAD600'][paqmid['PAD600'] == 6.0] = 0.0\n",
    "paqmid['PADtvcomp'] = paqmid['PAD590'] + paqmid['PAD600']\n",
    "paqmid['PADtvcomp'][paqmid['PADtvcomp'] > 70.0] = np.nan   \n",
    "paqmid['PADtvpoly'] = paqmid['PADtvcomp']*paqmid['PADtvcomp']\n",
    "\n",
    "# combine 99 and 01 with 03 and 05\n",
    "paqold = paqolder.append(paqmid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# walked or bicycled last 30 days:\n",
    "paqold['PAQ635'] = paqold['PAD020']\n",
    "paqold['PAQ635'][paqold['PAQ635'] == 3.0] = 2.0\n",
    "paqold['PAQ635'][paqold['PAQ635'] > 2.0] = np.nan\n",
    "paqold['PAQ635'][paqold['PAQ635'] == 2.0] = 0.0\n",
    "\n",
    "## of days walked/bicycled\n",
    "paqold['PAQ640'] = paqold['PAQ050Q']\n",
    "paqold['PAQ640'][paqold['PAQ640'] > 7500.0] = np.nan\n",
    "paqold['PAQ640'][paqold['PAQ635'] == 0.0] = 0.0\n",
    "paqold['PAQ640U'] = paqold['PAQ050U'].replace([1.0, 2.0, 3.0, np.nan], [365.0, 52.0, 12.0, 0.0])\n",
    "paqold['PAQ640'] = paqold['PAQ640']*paqold['PAQ640U']\n",
    "\n",
    "# minutes walked/bicycled\n",
    "paqold['PAD645'] = paqold['PAD080']\n",
    "paqold['PAD645'][paqold['PAD645'] > 7500.0] = 0\n",
    "paqold['PAD645'][paqold['PAQ635'] == 0.0] = 0.0\n",
    "paqold['PAD645min'] = paqold['PAD645']*paqold['PAQ640']\n",
    "\n",
    "# vigorous activity, yes or no?\n",
    "paqold['PADvig1'] = paqold['PAD200']  # yes/no in last 30 days\n",
    "paqold['PADvig1'][paqold['PADvig1'] == 3.0] = 2.0\n",
    "paqold['PADvig1'][paqold['PADvig1'] == 2.0] = 0.0\n",
    "paqold['PADvig1'][paqold['PADvig1'] > 6.0] = np.nan\n",
    "\n",
    "#  muscle strengthening, times/month?  (compare with vigorous activity in later years as vig2?)\n",
    "paqold['vigmask99'] = paqold['PAD200']\n",
    "paqold['vigmask99'][paqold['vigmask99'] == 2.0] = 0.0  # create mask for multiplying NANs back in at end\n",
    "paqold['vigmask99'][paqold['vigmask99'] == 3.0] = 0.0\n",
    "\n",
    "paqold['PADvig2'] = paqold['PAD460']*1.25  \n",
    "    # scale these values to better match vig2 from later years\n",
    "paqold['PADvig2'][paqold['PADvig2'].isnull()] = 0.0\n",
    "paqold['PADvig2'] = paqold['PADvig2']*paqold['vigmask99']\n",
    "    # so we code frequency as 0.0 for those who answered no in the yes/no section.  \n",
    "    # then we restore the NaN's for those who didn't answer the yes/no question\n",
    "\n",
    "#moderate activity, yes or no (using tasks around house(100) AND moderate activity(320))\n",
    "paqold['PADmod1'] = paqold['PAQ100']\n",
    "paqold['PADmod1'][paqold['PADmod1'] == 3.0] = 2.0\n",
    "paqold['PADmod1'][paqold['PAD320'] == 1.0] = 1.0\n",
    "paqold['PADmod1'][paqold['PADmod1'] == 2.0] = 0.0\n",
    "paqold['PADmod1'][paqold['PADmod1'] > 6.0] = np.nan\n",
    "\n",
    "# moderate activity, times/month\n",
    "paqold['modmask99'] = paqold['PAQ100']\n",
    "paqold['modmask99'][paqold['modmask99'] == 2.0] = 0.0\n",
    "paqold['modmask99'][paqold['modmask99'] == 3.0] = 0.0\n",
    "paqold['PADmod2'] = paqold['PAD120']\n",
    "paqold['PADmod2'][paqold['PADmod2'].isnull()] = 0.0\n",
    "paqold['PADmod2'] = paqold['PADmod2']*paqold['modmask99']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sedentary time\n",
    "paqmid2 = paq07.append(paq09)\n",
    "paqmid2['PAD590'][paqmid2['PAD590'] == 6.0] = 0.0\n",
    "paqmid2['PAD600'][paqmid2['PAD600'] == 6.0] = 0.0\n",
    "paqmid2['PADtvcomp'] = paqmid2['PAD590'] + paqmid2['PAD600']\n",
    "paqmid2['PADtvcomp'][paqmid2['PADtvcomp'] > 70.0] = np.nan   \n",
    "paqmid2['PADtvpoly'] = paqmid2['PADtvcomp']*paqmid2['PADtvcomp']\n",
    "\n",
    "paqnewer = paq11.append(paq13)\n",
    "paqnewer['PAQ710'][paqnewer['PAQ710'] == 8.0] = 0.0\n",
    "paqnewer['PAQ710'][paqnewer['PAQ710'] > 75.0] = np.nan\n",
    "paqnewer['PAQ715'][paqnewer['PAQ715'] == 8.0] = 0.0\n",
    "paqnewer['PAQ715'][paqnewer['PAQ715'] > 75.0] = np.nan\n",
    "paqnewer['PADtvcomp'] = (paqnewer['PAQ710'] + paqnewer['PAQ715'])\n",
    "paqnewer['PADtvpoly'] = paqnewer['PADtvcomp']*paqnewer['PADtvcomp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# combine 07 and 09 with 11 and 13\n",
    "paqnew = paqmid2.append(paqnewer)\n",
    "\n",
    "#walk or bicycle yes/no\n",
    "paqnew['PAQ635'][paqnew['PAQ635'] > 2.0] = np.nan\n",
    "paqnew['PAQ635'][paqnew['PAQ635'] == 2.0] = 0.0\n",
    "\n",
    "# frequency bike/walk\n",
    "paqnew['PAQ640'][paqnew['PAQ640'] > 70.0] = np.nan\n",
    "paqnew['PAQ640'][paqnew['PAQ635'] == 0.0] = 0.0\n",
    "paqnew['PAQ640U'] = 52.0\n",
    "paqnew['PAQ640'] = paqnew['PAQ640']*paqnew['PAQ640U']\n",
    "\n",
    "# minutes spent biking/walking\n",
    "paqnew['PAD645'][paqnew['PAD645'] > 7500.0] = np.nan\n",
    "paqnew['PAD645'][paqnew['PAQ635'] == 0.0] = 0.0\n",
    "paqnew['PAD645min'] = paqnew['PAD645']*paqnew['PAQ640']\n",
    "\n",
    "# vigorous activity, YES/NO\n",
    "paqnew['PADvig1'] = paqnew['PAQ650']  # vigorous rec (seems equivalent to 'last 30 days')\n",
    "paqnew['PADvig1'][paqnew['PAQ605'] == 1] = 1  # combine with vigorous work\n",
    "paqnew['PADvig1'][paqnew['PADvig1'] == 2] = 0.0\n",
    "paqnew['PADvig1'][paqnew['PADvig1'] > 6.0] = np.nan\n",
    "\n",
    "# vigorous activity, times/month\n",
    "paqnew['vigmask11'] = paqnew['PAQ605']\n",
    "paqnew['vigmask11'][paqnew['vigmask11'] == 2.0] = 0.0  # create mask for multiplying nans back in at end\n",
    "paqnew['vigmask11'][paqnew['vigmask11'] > 6.0] = np.nan\n",
    "paqnew['PADvig2'] = paqnew['PAQ655']*3.5  # of times per week (*3.5 to months, trying to normalize)vigorous rec\n",
    "paqnew['PAQ610'][paqnew['PAQ610'].isnull()] = 0.0\n",
    "paqnew['PADvig2'][paqnew['PADvig2'].isnull()] = 0.0\n",
    "paqnew['PADvig2'] = paqnew['PADvig2']*paqnew['vigmask11']\n",
    "paqnew['PADvig2'] = paqnew['PADvig2'] + paqnew['PAQ610']*3.5  # add in vigorous work\n",
    "    # so we code frequency as 0.0 for those who answered no in the yes/no section.  \n",
    "    # then we restore the NaN's for those who didn't answer the yes/no question\n",
    "    \n",
    "#moderate activity, yes or no\n",
    "paqnew['PADmod1'] = paqnew['PAQ620']\n",
    "paqnew['PADmod1'][paqnew['PAQ665'] == 1.0] = 1.0\n",
    "paqnew['PADmod1'][paqnew['PADmod1'] > 6.0] = np.nan\n",
    "paqnew['PADmod1'][paqnew['PADmod1'] == 2.0] = 0.0\n",
    "\n",
    "# moderate activity, times/month\n",
    "# NOTE THAT THIS MASK WORKS DIFFERENTLY THAN THE ABOVE\n",
    "paqnew['PAQ620'][paqnew['PAQ620'] == 2.0] = 0.0\n",
    "paqnew['PAQ665'][paqnew['PAQ665'] == 2.0] = 0.0\n",
    "paqnew['modmask11'] = paqnew['PAQ620'] + paqnew['PAQ665']\n",
    "paqnew['modmask11'][paqnew['modmask11'].isnull()] = 1.0\n",
    "paqnew['modmask11'][paqnew['modmask11'] > 0.0] = 1.0\n",
    "    # the mask holds 0's for all the subjects who answered NO to both work AND recreational \n",
    "    # moderate activity question.  the rest should stay nans (so all non 0's get multipled by 1).\n",
    "paqnew['PAQ625'][paqnew['PAQ625'] > 75.0] = np.nan\n",
    "paqnew['PAQ625'] = paqnew['PAQ625']*3.5\n",
    "paqnew['PAQ625'][paqnew['PAQ625'].isnull()] = 999.0\n",
    "paqnew['PAQ670'][paqnew['PAQ670'] > 75.0] = np.nan\n",
    "paqnew['PAQ670'] = paqnew['PAQ670']*3.5\n",
    "paqnew['PAQ670'][paqnew['PAQ670'].isnull()] = 999.0\n",
    "paqnew['PADmod2'] = paqnew['PAQ670'] + paqnew['PAQ625']\n",
    "paqnew['PADmod2'] = paqnew['PADmod2']*paqnew['modmask11']\n",
    "paqnew['PADmod2'][paqnew['PADmod2'] == 1998.0] = np.nan\n",
    "paqnew['PADmod2'][paqnew['PADmod2'] > 1000.0] = paqnew['PADmod2'] - 999.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combine data from before 2005 with later\n",
    "paq = paqold.append(paqnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pull out just the features we want\n",
    "paqF = paq[['SEQN', 'PAQ635', 'PAQ640', 'PAD645', 'PAD645min', 'PADvig1', 'PADvig2', 'PADmod1', 'PADmod2', 'PADtvcomp', 'PADtvpoly']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cardiovascular health, >40yrs only\n",
    "\n",
    "#### 1999 has only:\n",
    "\n",
    "'CDQ010' = shortness of breath on inclines\n",
    "\n",
    "#### the rest also have:\n",
    "'CDQ001': pain/discomfort in chest  \n",
    "'CDQ002': ...when walking uphill  \n",
    "'CDQ003': ...when walking ordinary pace  \n",
    "'CDQ008': severe pain lasting more than 30 min?  \n",
    "'CDQ009D': pain in upper sternum  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import data from 1999 - 2013\n",
    "cdq99 = pd.read_csv('CDCfiles/CDQ.csv')\n",
    "cdq01 = pd.read_csv('CDCfiles/CDQ_B.csv')\n",
    "cdq03 = pd.read_csv('CDCfiles/CDQ_C.csv')\n",
    "cdq05 = pd.read_csv('CDCfiles/CDQ_D.csv')\n",
    "cdq07 = pd.read_csv('CDCfiles/CDQ_E.csv')\n",
    "cdq09 = pd.read_csv('CDCfiles/CDQ_F.csv')\n",
    "cdq11 = pd.read_csv('CDCfiles/CDQ_G.csv')\n",
    "cdq13 = pd.read_csv('CDCfiles/CDQ_H.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# combine all data\n",
    "cdq = cdq01.append(cdq03).append(cdq05).append(cdq07).append(cdq09).append(cdq11).append(cdq13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from 99 on, shortness of breath on inclines:\n",
    "cdq['CDQ010'][cdq['CDQ010'] > 6] = np.nan\n",
    "# from 01 on, ever had pain/discomfort in chest:\n",
    "cdq['CDQ001'][cdq['CDQ001'] > 6] = np.nan\n",
    "# from 01 on, get pain/discomfort in chest when walking uphill or hurrying\n",
    "cdq['CDQ002'][cdq['CDQ002'] > 6] = np.nan\n",
    "cdq['CDQ002'][cdq['CDQ001'] == 2] = 2\n",
    "cdq['CDQ002'][cdq['CDQ002'] == 3] = 2\n",
    "# from 01 on, get pain/discomfort in chest when walking ordinary pace\n",
    "cdq['CDQ003'][cdq['CDQ003'] > 6] = np.nan\n",
    "cdq['CDQ003'][cdq['CDQ001'] == 2] = 2\n",
    "#from 01 on, severe chest pain lasting more than 30 min\n",
    "cdq['CDQ008'][cdq['CDQ008'] > 2.0] = np.nan\n",
    "cdq['CDQ008'][cdq['CDQ008'].isnull()] = 2.0\n",
    "#from 01 on, pain in upper sternum:\n",
    "cdq['CDQ009D'][cdq['CDQ009D'].isnull()] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pull out just the data we want\n",
    "cdqF = cdq[['SEQN', 'CDQ010', 'CDQ001', 'CDQ002', 'CDQ003', 'CDQ008', 'CDQ009D']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consumer Behavior\n",
    "\n",
    "#### from 07 and 09, goldmine:\n",
    "'CBQ020': fruits at home  \n",
    "'CBQ030': green veggies at home  \n",
    "'CBQ040': salty snacks   \n",
    "'CBQ060': soft drinks   \n",
    "'CBQ140': frequency of major shopping trips  \n",
    "'CBD150': time to get to grocery store  \n",
    "'CBD160': meals cooked at home per week\n",
    "\n",
    "#### 07, 09, 11, 13:\n",
    "'CBD070': money spent at grocery store  \n",
    "'CBD090': money spent nonfood groceries  \n",
    "'CBD110': money spent food other stores  \n",
    "'CBD120': money spent eating out  \n",
    "'CBD130': money spent carryout/delivered  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import data from all years available (2007 thorugh 2013)\n",
    "cbq07 = pd.read_csv('CDCfiles/CBQ_E.csv')\n",
    "cbq09 = pd.read_csv('CDCfiles/CBQ_F.csv')\n",
    "cbq11 = pd.read_csv('CDCfiles/CBQ_G.csv')\n",
    "cbq13 = pd.read_csv('CDCfiles/CBQ_H.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combine 2007 and 2009\n",
    "cbqold = cbq07.append(cbq09)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# recode NaNs\n",
    "cbqold['CBQ020'][cbqold['CBQ020'] > 75.0] = np.nan\n",
    "cbqold['CBQ030'][cbqold['CBQ030'] > 75.0] = np.nan\n",
    "cbqold['CBQ040'][cbqold['CBQ040'] > 75.0] = np.nan\n",
    "cbqold['CBQ060'][cbqold['CBQ060'] > 75.0] = np.nan\n",
    "\n",
    "cbqold['CBQ140'][cbqold['CBQ140'] > 75.0] = np.nan\n",
    "cbqold['CBD150'][cbqold['CBD150'] > 75000.0] = np.nan\n",
    "cbqold['CBD160'][cbqold['CBD160'] > 750.0] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combine 2007 and 2009 with 2011 and 2013\n",
    "cbq = cbqold.append(cbq11).append(cbq13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# recode NaNs\n",
    "cbq['CBD070'][cbq['CBD070'] > 750000.0] = np.nan\n",
    "cbq['CBD090'][cbq['CBD090'] > 750000.0] = np.nan\n",
    "\n",
    "cbq['CBD110'][cbq['CBD110'] > 750000.0] = np.nan\n",
    "cbq['CBD120'][cbq['CBD120'] > 750000.0] = np.nan\n",
    "cbq['CBD130'][cbq['CBD130'] > 750000.0] = np.nan\n",
    "\n",
    "cbq['CBDfr1'] = cbq['CBD070']/cbq['CBD090']\n",
    "cbq['CBDfr2'] = cbq['CBD070']/cbq['CBD120']\n",
    "cbq['CBDfr3'] = cbq['CBD070']/cbq['CBD130']\n",
    "\n",
    "cbq['CBDfr1'][cbq['CBDfr1'] == np.inf] = 20.0\n",
    "cbq['CBDfr2'][cbq['CBDfr2'] == np.inf] = 20.0\n",
    "cbq['CBDfr3'][cbq['CBDfr3'] == np.inf] = 20.0\n",
    "cbq['CBDfr1'][cbq['CBDfr1'] > 20] = 20.0\n",
    "cbq['CBDfr2'][cbq['CBDfr2'] > 20] = 20.0\n",
    "cbq['CBDfr3'][cbq['CBDfr3'] > 20] = 20.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pull out just the features we want\n",
    "cbqF = cbq[['SEQN', 'CBQ020', 'CBQ030', 'CBQ040', 'CBQ060', 'CBD070', 'CBD090', 'CBD110', 'CBD120', 'CBD130', 'CBQ140', 'CBD150', 'CBD160', 'CBDfr1', 'CBDfr2', 'CBDfr3']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smoking - 51,149 entries\n",
    "\n",
    "'SMQ020' : smoked 100 cigarettes in your life?  50/50, 0.1% NANs  \n",
    "'SMQ030 : age started smoking?  (set non-smokers to 85)  \n",
    "'SMQ040' : do you now smoke cigarettes?  \n",
    "'SMD650' : avg #cigs in last 30 days    __MISSING FROM 99 and 01__\n",
    "\n",
    "available all years?:\n",
    "ADD: SMD050Q/U: how long since quit  \n",
    "ADD: SMD057?  # smoked/day when quit?  \n",
    "ADD: SMD070  # smoked/day now?  \n",
    "ADD: SMD075: # years smoked this amount\n",
    "\n",
    "available from 05 on:\n",
    "SMD055: age when last smoked regularly?  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import data from 1999 - 2013\n",
    "smq99 = pd.read_csv('CDCfiles/SMQ.csv')\n",
    "smq01 = pd.read_csv('CDCfiles/SMQ_B.csv')\n",
    "smq03 = pd.read_csv('CDCfiles/SMQ_C.csv')\n",
    "smq05 = pd.read_csv('CDCfiles/SMQ_D.csv')\n",
    "smq07 = pd.read_csv('CDCfiles/SMQ_E.csv')\n",
    "smq09 = pd.read_csv('CDCfiles/SMQ_F.csv')\n",
    "smq11 = pd.read_csv('CDCfiles/SMQ_G.csv')\n",
    "smq13 = pd.read_csv('CDCfiles/SMQ_H.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combine all years\n",
    "smq = smq99.append(smq01).append(smq03).append(smq05).append(smq07).append(smq09).append(smq11).append(smq13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pull in age from demo\n",
    "smq = smq.set_index('SEQN').join(demo[['SEQN', 'RIDAGEYR']].set_index('SEQN')) \n",
    "smq['SEQN'] = smq.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings; warnings.filterwarnings('ignore')\n",
    "smq['SMQ020'][smq['SMQ020'] > 2.0] = np.nan\n",
    "smq['SMQ020'][smq['SMQ020'] == 2.0] = 0.0\n",
    "    ####  SMD020 can now serve as a mask!  set isnull() = 0.0 in target, then multiply w mask \n",
    "    ####  to put 0.0's for subjects who never really smoked, 1.0's to maintain those that did, and\n",
    "    ####  np.nan for the initial missing values\n",
    "\n",
    "# # per day when quit?\n",
    "smq['SMD057'][smq['SMD057'].isnull()] = 0.0\n",
    "smq['SMD057'] = smq['SMD057']*smq['SMQ020'] \n",
    "smq['SMD057'][smq['SMD057'] > 750.0] = np.nan\n",
    "\n",
    "# age when last smoked regularly\n",
    "smq['SMD055'][smq['SMD055'].isnull()] = 0.0\n",
    "smq['SMD055'][smq['SMD055'] > 750] = np.nan\n",
    "#age started smoking\n",
    "smq['SMD030'][smq['SMD030'].isnull()] = 0.0\n",
    "smq['SMD030'][smq['SMD030'] > 750] = np.nan\n",
    "# apply mask to keep those 0's that should be 0's 0's\n",
    "smq['SMD055'] = smq['SMD055']*smq['SMQ020'] \n",
    "smq['SMQ040'] = smq['SMQ040']*smq['SMQ020'] \n",
    "\n",
    "# years smoked regularly\n",
    "smq['SMDlen'] = smq['SMD055'] - smq['SMD030']\n",
    "smq['SMDlen'][smq['SMDlen'] < 0.0] = smq['RIDAGEYR'] - smq['SMD030']\n",
    "\n",
    "# intake x years\n",
    "smq['SMDamt'] = smq['SMDlen']*smq['SMD057']\n",
    "smq['SMDamt'][smq['SMDamt'] == 0.0] = smq['SMDlen']*smq['SMD650']\n",
    "smq['SMDamt'][smq['SMDamt'].isnull()] = 0.0\n",
    "smq['SMDamt'] = smq['SMDamt']*smq['SMQ020'] \n",
    "\n",
    "# fix age started smoking...\n",
    "smq['SMD030'][smq['SMQ020'] == 0.0] = 85.0\n",
    "smq['SMD030'][smq['SMD030'] > 700.0] = 85.0\n",
    "smq['SMD030'][smq['SMD030'].isnull()] = 85.0\n",
    "smq['SMD030'][smq['SMQ020'].isnull()] = np.nan\n",
    "    # this is a weird one, we'll try setting the age = 80.0 for all non-responderes \n",
    "    ###  WE COULD CHANGE THIS, FILL IN MEAN STARTING AGE FOR THE ~2,000 MISSING VALUES FROM 020\n",
    "    \n",
    "#smq['SMQ040'][smq['SMQ040'] == 3.0] = 0.0\n",
    "#smq['SMQ040'][smq['SMQ040'] == 1.0] = 3.0\n",
    "smq['SMQ040'][smq['SMQ040'] > 6.0] = np.nan\n",
    "smq['SMQ040'][smq['SMQ040'].isnull()] = 0.0\n",
    "smq['SMQ040'] = smq['SMQ040']*smq['SMQ020'] \n",
    "\n",
    "smq['SMD650'][smq['SMD650'] == 777.0] = np.nan\n",
    "smq['SMD650'][smq['SMD650'] == 999.0] = np.nan\n",
    "smq['SMD650'][smq['SMD650'].isnull()] = 0.0\n",
    "smq['SMD650'] = smq['SMD650']*smq['SMQ020']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pull out just the features we want\n",
    "smqF = smq[['SEQN', 'SMQ020', 'SMD030','SMQ040', 'SMD650', 'SMD057', 'SMDlen', 'SMDamt']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Income\n",
    "\n",
    "#### Available for 07, 09, 11, 13\n",
    "\n",
    "'IND235': monthly family income (categorical 1-12)  .......NANs: 1/10  \n",
    "'INDFMMPI': monthly poverty index (ordinal 0 to 5)  .......NANs: 1/10  \n",
    "'INDFMMPC': monthly poverty index (categorical 1,2,3)  .......NANs: 1/20?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import data from all years available\n",
    "inc07 = pd.read_csv('CDCfiles/INQ_E.csv')\n",
    "inc09 = pd.read_csv('CDCfiles/INQ_F.csv')\n",
    "inc11 = pd.read_csv('CDCfiles/INQ_G.csv')\n",
    "inc13 = pd.read_csv('CDCfiles/INQ_H.csv')\n",
    "# combine 2007 through 2013\n",
    "inc = inc07.append(inc09).append(inc11).append(inc13)\n",
    "# recode NaNs\n",
    "inc['IND235'][inc['IND235'] > 75.0] = np.nan\n",
    "inc['INDFMMPC'][inc['INDFMMPC'] > 6.0] = np.nan\n",
    "# pull out the features of interest\n",
    "incF = inc[['SEQN', 'IND235', 'INDFMMPI', 'INDFMMPC']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Current medical conditions\n",
    "\n",
    "'MCQ160A': ever told you have arthritis?   ... ... NANs: 1/2, 25% YES  \n",
    "'MCQ160I' (/160M) : ever told you have thyroid disease?   .... NANs: 1/2, 7% YES  \n",
    "...(also: ever told you had heart attack, stroke, emphysema, bronchitis, coronary heart disease)  \n",
    "\n",
    "'MCQ053': taking treatment for anemia?   ... ... full response, 3% positive\n",
    "'MCQ250A' (/300C) : blood relatives have diabetes?     ... ... NANs: 1/2  \n",
    "'MCQ250D': blood relatives have arthritis?     ... ... NANs: 1/2  \n",
    "'MCQ250E': (in osteoporosis section later) blood relatives have osteopororis?     ... ... NANs: 1/2  \n",
    "'MCQ250F': blood relatives have hypertension/stroke?     ... ... NANs: 1/2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import data from all years available\n",
    "mcq99 = pd.read_csv('CDCfiles/MCQ.csv')\n",
    "mcq01 = pd.read_csv('CDCfiles/MCQ_B.csv')\n",
    "mcq03 = pd.read_csv('CDCfiles/MCQ_C.csv')\n",
    "mcq05 = pd.read_csv('CDCfiles/MCQ_D.csv')\n",
    "mcq07 = pd.read_csv('CDCfiles/MCQ_E.csv')\n",
    "mcq09 = pd.read_csv('CDCfiles/MCQ_F.csv')\n",
    "mcq11 = pd.read_csv('CDCfiles/MCQ_G.csv')\n",
    "mcq13 = pd.read_csv('CDCfiles/MCQ_H.csv')\n",
    "osq05 = pd.read_csv('CDCfiles/OSQ_D.csv')\n",
    "osq07 = pd.read_csv('CDCfiles/OSQ_E.csv')\n",
    "osq09 = pd.read_csv('CDCfiles/OSQ_F.csv')\n",
    "osq13 = pd.read_csv('CDCfiles/OSQ_H.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# recoding questions that changed in later years\n",
    "mcq99['MCQ300A'] = mcq99['MCQ250F']\n",
    "mcq01['MCQ300A'] = mcq01['MCQ250F']\n",
    "mcq03['MCQ300A'] = mcq03['MCQ250F']\n",
    "\n",
    "mcq99['OSQ150'] = mcq99['MCQ250E']\n",
    "mcq01['OSQ150'] = mcq01['MCQ250E']\n",
    "mcq03['OSQ150'] = mcq03['MCQ250E']\n",
    "\n",
    "mcq99['MCQ300C'] = mcq99['MCQ250A']\n",
    "mcq01['MCQ300C'] = mcq01['MCQ250A']\n",
    "mcq03['MCQ300C'] = mcq03['MCQ250A']\n",
    "\n",
    "mcq05['OSQ150'] = osq05['OSQ150']\n",
    "mcq07['OSQ150'] = osq07['OSQ150']\n",
    "mcq09['OSQ150'] = osq09['OSQ150']\n",
    "mcq13['OSQ150'] = osq13['OSQ150']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combine all years\n",
    "mcq = mcq99.append(mcq01).append(mcq03).append(mcq05).append(mcq07).append(mcq09).append(mcq11).append(mcq13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filter NaNs\n",
    "mcq['MCQ300C'][mcq['MCQ300C'] > 5.0] = np.nan\n",
    "mcq['MCQ300C'][mcq['MCQ300C'] == 2.0] = 0\n",
    "\n",
    "mcq['MCQ300A'][mcq['MCQ300A'] > 5.0] = np.nan\n",
    "mcq['MCQ300A'][mcq['MCQ300A'] == 2.0] = 0\n",
    "\n",
    "mcq['OSQ150'][mcq['OSQ150'] > 5.0] = np.nan\n",
    "mcq['OSQ150'][mcq['OSQ150'] == 2.0] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pull out the features we want\n",
    "mcqF = mcq[['SEQN', 'MCQ300A', 'OSQ150', 'MCQ300C']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Current medications\n",
    "#### Some patients are already being treated for various conditions.  Here we extract records, below we will combine them with 'at risk' measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import data from all years available\n",
    "bpq99 = pd.read_csv('CDCfiles/BPQ.csv')\n",
    "bpq01 = pd.read_csv('CDCfiles/BPQ_B.csv')\n",
    "bpq03 = pd.read_csv('CDCfiles/BPQ_C.csv')\n",
    "bpq05 = pd.read_csv('CDCfiles/BPQ_D.csv')\n",
    "bpq07 = pd.read_csv('CDCfiles/BPQ_E.csv')\n",
    "bpq09 = pd.read_csv('CDCfiles/BPQ_F.csv')\n",
    "bpq11 = pd.read_csv('CDCfiles/BPQ_G.csv')\n",
    "bpq13 = pd.read_csv('CDCfiles/BPQ_H.csv')\n",
    "diq99 = pd.read_csv('CDCfiles/DIQ.csv')\n",
    "diq01 = pd.read_csv('CDCfiles/DIQ_B.csv')\n",
    "diq03 = pd.read_csv('CDCfiles/DIQ_C.csv')\n",
    "diq05 = pd.read_csv('CDCfiles/DIQ_D.csv')\n",
    "diq07 = pd.read_csv('CDCfiles/DIQ_E.csv')\n",
    "diq09 = pd.read_csv('CDCfiles/DIQ_F.csv')\n",
    "diq11 = pd.read_csv('CDCfiles/DIQ_G.csv')\n",
    "diq13 = pd.read_csv('CDCfiles/DIQ_H.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combine data from all years\n",
    "bpq = bpq99.append(bpq01).append(bpq03).append(bpq05).append(bpq07).append(bpq09).append(bpq11).append(bpq13)\n",
    "diq = diq99.append(diq01).append(diq03).append(diq05).append(diq07).append(diq09).append(diq11).append(diq13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# recode NaNs to 'not treated' in this case.  a few of these may be wrong, but its better not to \n",
    "#lose thousands of samples here just because we don't know 100% certain they aren't on meds\n",
    "bpq.BPQ040A[bpq.BPQ040A > 1.0] = 0.0\n",
    "bpq.BPQ050A[bpq.BPQ050A > 1.0] = 0.0\n",
    "bpq.BPQ080[bpq.BPQ080 > 1.0] = 0.0\n",
    "bpq.BPQ100D[bpq.BPQ100D > 1.0] = 0.0\n",
    "diq.DIQ010[diq.DIQ010 > 1.0] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pull out the features we want\n",
    "bpbpF = bpq[['SEQN', 'BPQ050A']]  #try BPQ040A as alternative\n",
    "bpcholF = bpq[['SEQN', 'BPQ100D']]  #try BPQ080 as alternative\n",
    "diqF = diq[['SEQN', 'DIQ010']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save cleaned data into .csv for subsequent modeling..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cholesterol targeting can be adjusted here (predict based off of total, LDL - HDL, or triglycerides...)\n",
    "# with cholesterol, we can try modeling total cholesterol, or LDL - HDL,\n",
    "# here we set target as total cholesterol\n",
    "target = 'LBXTC' \n",
    "cholF['combo'] = (cholF['LBDLDL'] - cholF['LBDHDD'])\n",
    "totalcholF = cholF[['SEQN', target]]\n",
    "          \n",
    "# join together all features and targets into the starting dataframe 'XY'    \n",
    "XY = demoFdummy.set_index('SEQN').join(bodyF.set_index('SEQN')).join(alcF.set_index('SEQN')).join(dbqF.set_index('SEQN')).join(paqF.set_index('SEQN')).join(smqF.set_index('SEQN')).join(cbqF.set_index('SEQN')).join(mcqF.set_index('SEQN')).join(bpxF.set_index('SEQN')).join(bpbpF.set_index('SEQN')).join(totalcholF.set_index('SEQN')).join(bpcholF.set_index('SEQN')).join(ghbF.set_index('SEQN')).join(diqF.set_index('SEQN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XY.to_csv('NHANES_XY.csv')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tf35]",
   "language": "python",
   "name": "conda-env-tf35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
